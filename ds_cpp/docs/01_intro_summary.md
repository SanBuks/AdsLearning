# 1. 计算机与算法
## 1.1 背景
- 起源: 1946年, ENIAC 问世开启了现代电子数字计算机的时代, 计算机科学随之诞生
- 计算机科学: 研究计算方法与过程的规律和技巧的学科, 计算机只是帮助计算和解决问题的工具
- 通过计算机来解决问题的本质:
  - 深入思考与分析获得对问题本质的透彻理解
  - 按照长期积淀而成的框架与模式设计出合乎问题内在规律的算法
  - 选用, 改进或定制足以支撑算法高效实现的数据结构
  - 在真实的应用环境中充分测试, 调校和改进
- 算法的四个主要方面:
  - 算法构成的基本要素
  - 算法效率的衡量尺度
  - 计算复杂度的分析方法与界定技巧
  - 算法设计的基本框架与典型模式

## 1.2 算法的基本要素
- 算法定义: 基于特定的计算模型, 为解决某个问题而设计的一组顺序的指令序列
- 算法的 5 种基本要素和其他评价标准(#bubble_sort.h), 注意算法基本要素不含正确性
- 程序和算法的区别: 程序未必是有穷的, 程序 != 算法
- 算法分析主要分为两个方面:
  - 证明正确性即反应正确基本性质的不变性和输入规模的单调性
  - 运行时间空间的复杂度度量

# 2. 复杂度度量
## 2.1 时间复杂度与空间复杂度
- 任何一次算法中, 对内存的操作次数都不会多于基本操作次数, 所以一般只注重于时间复杂度
- 时间复杂度引入渐进分析的原因:
  - 对于用算法 A 来解决具体事件 p 的度量 $T_A(p)$ 因具体事件变化而频繁改变
  - 用输入规模 n 划分等价类, 对事件规模 n 的时间最长度量 $T_A(n)$ 因输入规模不一而改变
  - 因为小规模问题的时间度量差异很小, 随着规模越大差异越大, 因此引入渐进分析

## 2.2 渐进分析
- 渐近分析: 注重时间复杂度总体的变化趋势的分析方法, 通常关注增长速度的最坏情况, 其中通用 3 种记号:
  - $T(n) = \Theta(f(n))$ : $n\rightarrow\infty,\exist c_1,c_2,有c_1f(n)\leq T(n) \leq c_2f(n)$
  - $T(n) = O(f(n))$ : $n\rightarrow\infty,\exist c>0,有T(n)\leq c f(n)$
  - $T(n) = \Omega(f(n))$ : $n\rightarrow\infty,\exist c>0,有 T(n)\geq c f(n)$
  - 上述定义中的 $c$ 起到了忽略常数因子的作用, 在 $2n^2+3n-2 = O(n^2)$ 证明中可以看出来
- 2 种性质: 忽略常数项, 忽略低次项

## 2.3 计算模型与基本操作
- 计算模型定义: 忽略机器和语言等差异, 将所有指令看作看作模型的基本操作, 计算执行的总次数来进行客观估计:
- 图灵机:
  - 有限长的纸带
  - 有限种类的字符表
  - 读写头
  - 状态
  - 函数\[条件(当前状态q, 读到字符c) => 动作(新字符d, 转向L/R, 新状态p)]  (h为终止状态)
- RAM(Random Access Machine):
  - 无限的寄存器
  - 固定的指令, 如: 寻址指令, 判定指令, 转向指令(类似汇编)
  - 高级程序语言在一定程度上等价于RAM模型
 
# 3. 复杂度分析
## 3.1 高效解
- $O(1)$: 常数项复杂度, 与输入规模无关(#ordinary_element.h)
- $O(\log{n})$: 对数复杂度, 不标明底, 因为底可以互相转换(#count_ones.h)
- $O(\log{n^n})$: 对数多项式复杂度

## 3.2 有效解
- $O(n)$: 线性复杂度
- $O(n^c)$: 多项式复杂度(#bubble_sort.h)

## 3.3 难解
- $O(2^n)$: 指数复杂度, 注意输入规模的衡量标准不同会影响分析结果(#power2.h)
- $O(a^n)$: 指数多项式复杂度, 随 n 增长极快
- NPC 问题: 不存在多项式时间内解决的方法, 如: 美国选举票数问题(O(2^n))

## 3.4 复杂度层次
- $O(1), O(\log{\log{n}}), O(\log{n})$
- $O(\sqrt{n}), O(n)$
- $O(n\log{\log{n}}),O(n\log{n})$
- $O(n^2),O(n^c)$
- $O(2^n)$

## 3.5 关于输入规模
- 输入规模有两种理解:
  - 严格基于所需的规模空间, 如二进制位数(#count_ones.h)
  - 只基于数值本身, 可称为伪 XXX 复杂度

# 4. 解决问题的三种方法
## 4.1 递归
- 定义: 将问题分为若干个问题调用自身来解决
- 作用: 简洁, 可读但不一定提高效率
- 基本要素: 递归基 和 递归方向
- 类别:
  - 减而治之: 线性递归, 每次调用减少问题规模若干个
  - 分而治之: 多向递归, 将问题分成若干个小问题解决
- 分析方法: 递归跟踪(递归树), 递归方程(主方法)
- 消除方法: 栈来模拟递归, 尾递归转换为迭代

## 4.2 迭代
- 定义: 用变量的原值推算出新的值, 比如循环
- 分析: (通过计算循环中的次数)
  - 等比(几何)级数: $\sum_{k=0}^{n}a^k = O(a^{n})$
  - 幂方级数: $\sum_{k=0}^{n}n^k = O(n^{k+1})$
  - 等差级数: $\sum_{k=0}^{n}kd=O(n^2)$
  - 收敛级数: 先判断为收敛级数 , 比如 $\sum_{k=1}^{n}\frac{1}{2^k}=O(1)$
  - 调和级数: $\sum_{k=1}^n\frac{1}{k}=\Theta(logn)$
  - 对数级数: $\sum_{k=1}^nlog(k)=\Theta(nlogn)$
  - 或者 通过画出 x-y 轴图像来判断

## 4.3 动态规划
- 递归形式: 记忆法
- 迭代形式: 状态转移方程
- 动态规划步骤: 
  - 确定 dp 数组和下标含义
  - 递推公式
  - dp 初始化
  - 确定遍历顺序
  - 举例

## 5. 抽象数据类型
- DS(Data Struct): 若干具体数据项和具体操作
- ADT(Abstract Data Type): 数据模型和定义在模型上的一组操作, 超脱于语言和实现方式
- DS 与 ADT: DS 是基于某种特定语言和背景, 实现 ADT 得到的对象和具体操作
  - ADT 类比 int
  - DS 类比 int a; 中的 a
- 封装定义: (数据类型的发展遵从 OOP 的思想, 进行封装)
  - 将数据项与相关的操作结合为一个整体(结构体) 
  - 并从外部的可见性划分为若干级别(访问控制符)
  - 外部使用与实现相分离, 提供外部接口, 隐藏内部细节(解耦)